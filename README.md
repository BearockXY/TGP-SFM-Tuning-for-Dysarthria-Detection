# Use-TGP-for-tuning-Speech-Fundation-Model-for-Dyasarthria-Speech-Detection
This repo is to post the implementation for the Interspeech 2025 paper: Mitigating Overfitting During Speech Foundation Model Fine-tuning: Applications to Dysarthric Speech Detection. Authors: Yan Xiong, Visar Berisha, Julie Liss, and Chaitali Chakrabarti.

It is all the Python scripts used to run experiments for the paper. It is recommended to start with the bash script to understand how the implementaion runs.

Dataset: We would like to clarify that the speech data used in our study was initially collected as far back as the 1990s. At the time, the consent forms signed by participants did not include provisions for public data sharing. More recently, however, the consent process has been updated to explicitly allow for such use. Before we can release any data, we need to ensure that we only include samples from participants who provided consent under the revised terms.

The model is too large to be included. Please feel free to mail the author for the pre-trained model if needed. 
Contact mail: yxiong35@asu.edu.
